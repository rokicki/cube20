<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=fpjTOVmNbO4Lz34iLyptLUXza5VhXqVC6o75Eld_V98');ol{margin:0;padding:0}table td,table th{padding:0}.c11{-webkit-text-decoration-skip:none;color:#000000;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:35pt;font-family:"Times New Roman";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Times New Roman";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Times New Roman";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:35pt;font-family:"Times New Roman";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Arial";font-style:normal}.c2{padding-top:0pt;padding-bottom:10pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:center}.c0{padding-top:0pt;padding-bottom:10pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:left}.c4{vertical-align:baseline;font-size:15pt;font-family:"Times New Roman";font-weight:400}.c7{vertical-align:baseline;font-size:21pt;font-family:"Times New Roman";font-weight:700}.c10{vertical-align:baseline;font-size:15pt;font-family:"Times New Roman";font-weight:700}.c3{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c5{height:11pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.1500000000000001;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Calibri"}p{margin:0;color:#000000;font-size:11pt;font-family:"Calibri"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.1500000000000001;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c3"><p class="c2"><span class="c11">Climbpro 24 and the big BFS problem.</span></p><p class="c2 c5"><span class="c11"></span></p><p class="c0"><span class="c6">An introduction to the problem.</span></p><p class="c0"><span class="c1">Here is a rather short and condensed write-up, of my program/method for solving computationally HARD sliding block puzzles. To put computationally HARD in perspective, the puzzle in question is Climpro 24 by Minoru Abe:</span></p><p class="c0"><span class="c1">http://www.johnrausch.com/slidingblockpuzzles/pro24-1.htm</span></p><p class="c0"><span class="c1">And its configuration space is enormous, or more precisely on the order of 10^16. &nbsp;I have good reason to believe that Petabytes of storage are needed to do the full BFS (Breadth First Search) for a provable optimal solution. In the following notes, I will assume a little background, generally, the definition of a sliding block puzzle is quite intuitive, and I guess most people reading this note are familiar with those puzzles, and are either familiar with some solver programs, or have a sound understanding of computer science, sorting, hashing and graph algorithms.</span></p><p class="c0"><span class="c1">Essentially, because of the very non-algebraic structure of sliding block puzzles, (as compared to other permutation based puzzles such as Rubik&rsquo;s cube which have a group structure), the only known way to prove a puzzle solution is shortest, is by doing a full BFS search of the puzzle configuration space. In most known sliding block puzzles, that search space/graph is modest by modern computer standards, (less than about a million nodes), so computers are much better than humans solving those puzzles by brute force. </span></p><p class="c0"><span class="c1">Climpro 24 is a notable exception, as its configuration space is indeed ginormous. It has been solved already, first by its creator, and the shortest known solution of 227 moves was found by an earlier solver program (written by Noel Dillabough). However the solution is not provably shortest, as the BFS state tree was pruned using a clever heuristic criteria (For example you can say a state is closer to the solution by measuring how high you managed to &quot;climb&quot;, but the criteria used was a bit more clever than that). In the following discussion, I will refer, and give numbers that are specific to Climbpro 24, &nbsp;but all methods, &nbsp;are applicable to a general sliding block puzzles and some to general graph BFS search. </span></p><p class="c0"><span class="c1">I have tried to write a program that would compute and traverse the huge BFS levels for this puzzle as far as I could possibly go. From the outset it was clear to me that a full traversal reaching the solution would not be possible, however it was an interesting and fun challenge, to try and see how far I could get the BFS to using the limited resources I had at hand (In particular no more than 2.7 TeraBytes disk partition). The actual output of the program was a log of its execution containing the size of each level it has traversed. The end product was a result of two to three months of (partial) work and is quite a sophisticated and involved implementation, even though the problem sounds straightforward. </span></p><p class="c0"><span class="c6">The method/algorithm used.</span></p><p class="c0"><span class="c1">So, for starters, just define level N of the BFS search to be consisting of all board positions, that are reachable by a MINIMAL path of length N from our starting position. You may imagine the graph visually as consisting of spheres, where level N is a &quot;sphere&quot; of points with &quot;radius&quot; N around the initial position. Given boards/positions at level N you can generate level N+1 by moving one piece, and then checking if you have found a new position. The hardness of the problem comes from the need to do that check of a huge boards collection of course.</span></p><p class="c0"><span class="c1">The first well known BFS space optimization (which was self re-discovered), is that if we have reached level N we may forget about all boards at levels less than N-1, as an edge from level N board to those boards does not exist. It may be argued that if we want to find a true solution sequence, i.e. the actual path to the solution state, then we need back tracking pointers at all those early levels, but actually that is not necessary. It is enough to keep maybe level N-60, or in general keep only 1/K (K=60) in that example, of the levels. Then the backtracking can be done by reversing the BFS search, starting at the solution board, and stopping when level N-60 is hit. &nbsp;Anyway it was not relevant as the full BFS was not expected to reach any solution anyways....</span></p><p class="c0"><span class="c1">Another space optimization which is not so well known is in the encoding of the board positions (I did not think of it originally, but I have been kindly advised about by Noel, and I lately I saw it was known also by earlier solver writers). Essentially there are 23 pieces of 9 types and there are 4 empty spaces on the board. So a string of 27 characters from an alphabet with 10 symbols which defines the permutation of the pieces/holes you get when scanning a board position, left to right, top to bottom can be used to uniquely determine that board (Notice that we use 10 symbols because we do not care about permutation of pieces with the same shape type). A simple Huffman encoding of those 10 symbols can be used to reduce the data of a board representation encoding to be less than 12 bytes. &nbsp;Again this method is general and can be applied to any sliding block puzzle.</span></p><p class="c0"><span class="c1">OK, so now our problem is only to do this BFS search, however it is becoming not so trivial doing the searches as our levels get bigger and bigger. When you need to search each new generated board against a terabyte of previously generated boards and then also update this board database/hash accordingly you have a big problem on your hand. Anyway what I had at hand is one rather old Netapp disk partition with something that is probably no more than 50/Mb sec I/O bandwidth, not to mention random access time. Yet my final implementation managed something like 10 Giga searches per hour (on that terabyte) so here is how it was done.</span></p><p class="c0"><span class="c4">The first thing to do is to try and work on some reasonable part of data in memory. This is done by a bucket hash. The bucket hash is a function from boards to a number </span><span class="c10">BNUM</span><span class="c4">&nbsp;(say 8192) of buckets. Assume now in each level there are </span><span class="c10">BNUM </span><span class="c1">files. Each of those files is supposed to be small enough so that a few can fit together in RAM memory. Once a level processing is finished each of those files will contain a sorted list of the board positions at the level whose hash is matching that bucket index. Those sorted buckets lists, for level N and level N-1 are our &#39;database&#39; from which level N+1 is to be generated. To generate level N+1 we do the following:</span></p><p class="c0"><span class="c7">A.</span><span class="c1">&nbsp;Pass on all level N buckets, (one by one or in parallel using several processors). For each such bucket, we pass on all the boards in the bucket and generate all moves from those boards, throwing the resulting boards into relatively big unsorted bucket files for level N+1. After this is done, we have indeed all the level N+1 positions in those unsorted buckets, but there are lot of repetitions and boards from level N and N+1 there. When this algorithm was used actually 4/5 of the disk space and I/O time was wasted on those unwanted boards, as the unsorted buckets were roughly 5 times the size of the final sorted and pruned ones.</span></p><p class="c0"><span class="c7">B.</span><span class="c1">&nbsp;Now, do a second pass. In that pass, for each bucket B, read into memory the unsorted bucket at level N+1, and the level N and level N-1 sorted buckets. Then at first using (in memory) &nbsp;search in the sorted buckets, we throw about half of the unsorted positions which do not belong to level N+1 because they were at a level &lt;=N, and then sort (in memory) the remaining boards, throw away duplicates , and voila! &nbsp;Write the sorted level N+1 bucket to the disk.</span></p><p class="c0"><span class="c1">Actually the program does those two steps concurrently, essentially starting at step B. &nbsp;Then , after writing the sorted buckets to the disk, it immediately proceeds to generate moves from this new sorted bucket that is already in memory, but that is not such an important optimization. The actual sorting method used is not a full sort, rather a variant of &nbsp;bucket sort, using a uniform hash function, but that is an implementation detail that is not so important/novel, what is important, is that all sorting and searching are done on relatively modest one bucket sized data, that fits into RAM snuggly.</span></p><p class="c0"><span class="c1">Note that as far as disk I/O is concerned seeks should be avoided as possible. They are needed though at stage A as we are throwing data to all buckets concurrently. However keeping a reasonable amount of buffers in memory, we can reach a reasonable amount of seeks. For example there are 8192 buckets, then having only 64 MBytes of buffer space means, we can write to disk only a &quot;page&quot; of size about 8K which is within reason. Since Linux and other OS&#39;s do not like to have too many file descriptors open concurrently each file may contain actually several buckets, where a linked list of pages is implemented for each bucket. This means by the way that write seeks are done less often, but read seeks are more as the list s have to be traversed when reading a bucket.</span></p><p class="c0"><span class="c4">Now we finally reach the most important and novel optimization which was discovered, and which made about a factor of a 4 improvement in both I/O and disk space (And a factor of 20 of network traffic on a hypothetical distributed setting). That is the non-uniform bucket hash trick. If you think of it, the fact that the unsorted buckets are occupying 5 times as much disk space as the sorted ones is quite disturbing, especially as storage and I/O are essentially the limiting factors. However as hash functions are designed to be as even/random as possible, the fact is, there is no way to sort the N+1 buckets on the fly at stage </span><span class="c10">A</span><span class="c1">&nbsp;above, that is because only a tiny part of each output bucket is kept in memory as all output buckets are generated at once and must be flushed to disk through the memory buffers. Also previous generation&rsquo;s buckets different than the one currently processed are not resident in memory. &nbsp;</span></p><p class="c0"><span class="c1">The solution to this conundrum is to use a very non-random hash function to determine the bucket of a board. If we could find a hash function that is probabilistically &lsquo;continous&rsquo;, i.e. tends to stay constant as the graph is traversed, the problem will be &nbsp;solved. What we are looking for is a hash function H(b) that tends to give the same bucket (a number between 0 to BNUM) for two adjacent boards b1 and b2 (separated by one move). We need H(b1)=H(b2) with high enough probability. We also need this hash function to be as uniform as possible but we &nbsp;considerable variance in the bucket sizes an still be tolerated assuming the bigger buckets don&rsquo;t get too big. &nbsp;Let&rsquo;s assume for example that the hash stays constant with probability 0.95.</span></p><p class="c0"><span class="c4">In that case, at step </span><span class="c10">A</span><span class="c4">, When working on bucket number &#39;b&#39; on level N , 19/20 of the generated candidates for level N+1 would fall into the same bucket (As opposed to 1/</span><span class="c10">BNUM </span><span class="c4">for a normal pseudorandom hash function). All those boards can then be sorted and pruned on the fly (As we have level N and level N-1 bucket &#39;b&#39; in memory). We are then left with only 1/20 of the amount of unsorted buckets that we had before which is certainly a big improvement! Those smaller unsorted buckets are now treated in step </span><span class="c10">B</span><span class="c1">&nbsp;as before and merged with the sorted ones.</span></p><p class="c0"><span class="c1">OK, All that is just fine and dandy, but how to find such a wonderful hash function that is also easy to compute? The answer is quite elegant and simple once you find it...</span></p><p class="c0"><span class="c1">This wonder hash can be generated by taking the original board string of 27 symbols, and then making it into a shorter string by throwing out the symbols corresponding to the empty spaces and the little pieces (1x1 , 1x2 , 2x1). The result is a string of length 13 using 7 symbols representing the order of the bigger pieces. Apply your favorite uniform pseudo random hash to that string and that&rsquo;s it! I have found empirically that this hash indeed works with probability of about 95% for the Climbpro 24 puzzle, but the approach is general and would work for any sliding puzzle composed of different piece types. That is simply because the &quot;bigger&quot; pieces are much harder to move compared to smaller piece their order tends to be constant. The hash is of course non-uniform, especially at the start of the BFS where there is only one bucket, but as we go deeper into the big levels that matter, the big pieces gets permuted too, and there is a reasonable distribution.</span></p><p class="c0"><span class="c1">Another thing that is nice about the scheme is that it lends itself quite naturally to parallel/distributed architecture. Imagine that each processor, is responsible to one bucket, and stores that data locally. In the original uniform hash scheme, there was a huge communication bottleneck where the huge unsorted bucket data had to be spread over the network from one processor to another. &nbsp;Now this bottleneck is reduced by a factor of 20, which is quite cool.</span></p><p class="c0"><span class="c6">Results.</span></p><p class="c0"><span class="c4">The final version of the program was run on an 8 cores Xeon server that was connected to a Netapp storage 2.7 Terabytes partition. It took about 2 weeks (with some restarts) to reach and completely sort level 152 of the BFS. &nbsp;I ran it on April 2011 on an unused old server at my workplace, an Intel Xeon E5310 with two quad core processors @1.6 GHz, which is actually quite slow in single thread performance. Nevertheless when working with 8 threads it seemed that CPU and I/O were more or less balanced with &lsquo;top&rsquo; command showing 70% to 80% CPU usage on all cores. That configuration sustained a performance of about 2 Giga sorted boards per hour. Notice that the amount of searches and sorting is much bigger than the 2G as about 10G searches are performed in order to get the clean sorted results, then of course there is the actual board encode/decode an move generation taking CPU time. The final level sizes are as follows:</span></p><p class="c0"><span class="c9">140 : 12276428414 1.13318769001 9.38329076356e-05<br>141 : 13912053649 1.13323298763 4.52976215415e-05<br>142 : 15766282793 1.13328220195 4.92143229369e-05<br>143 : 17867897511 1.13329804784 1.58458889221e-05<br>144 : 20248733406 1.13324656096&nbsp; -5.14868758683e-05<br>145 : 22945264195 1.13317034379&nbsp; -7.62171735744e-05<br>146 : 25998914195 1.13308410721&nbsp; -8.6236584425e-05<br>147 : 29456044859 1.13297211715&nbsp; -0.000111990060358<br>148 : 33366093846 1.1327418194&nbsp; -0.000230297742758<br>149 : 37785919362 1.13246457726&nbsp; -0.000277242146831<br>150 : 42779023472 1.13214192467&nbsp; -0.000322652584053<br>151 : 48416247686 1.13177543002&nbsp; -0.000366494648806<br>152 : 54775551124 1.13134647442&nbsp; -0.000428955607472</span></p><p class="c0 c5"><span class="c9"></span></p><p class="c0"><span class="c1">The second number in each row is the growth ratio from the previous level. The third number is the additive change in the ratio. As can be seen there is an almost constant exponential growth in the level sizes with a doubling taking about 5 levels. &nbsp;Since each board occupies 12 bytes after Huffman encoding, the sorted buckets for three top levels already occupy 1.7 Terabytes of disk space &hellip;.</span></p><p class="c0"><span class="c1">The program correctness was verified by comparing the level size numbers with numbers that Noel Dillabough used to get before when he attempted a similar search. The numbers we got until generation 142 were matching, so the probability of a bug is rather low, also hardware error probably did not occur, as the buckets were verified to be sorted, after being read from the disk.</span></p><p class="c0 c5"><span class="c8"></span></p><p class="c0 c5"><span class="c8"></span></p></body></html>